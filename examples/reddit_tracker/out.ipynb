{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true,
    "inputHidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at 'In [12]'.</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at 'In [12]'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020645,
     "end_time": "2020-03-29T11:46:38.408289",
     "exception": false,
     "start_time": "2020-03-29T11:46:38.387644",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Creating a Reddit tracker\n",
    "\n",
    "This notebook details:  \n",
    "1. Setting up a Reddit API wrapper and querying Reddit\n",
    "2. Extracting names from Reddit submission titles with SpaCy\n",
    "3. Saving the results as a dataframe\n",
    "4. Counting the top mentioned names and plotting them with Plotly\n",
    "5. Saving the outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013192,
     "end_time": "2020-03-29T11:46:38.437200",
     "exception": false,
     "start_time": "2020-03-29T11:46:38.424008",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "papermill": {
     "duration": 17.577225,
     "end_time": "2020-03-29T11:46:56.029061",
     "exception": false,
     "start_time": "2020-03-29T11:46:38.451836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "import os\n",
    "import time\n",
    "import praw\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "import json\n",
    "from datetime import datetime, timezone\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 0.022744,
     "end_time": "2020-03-29T11:46:56.064290",
     "exception": false,
     "start_time": "2020-03-29T11:46:56.041546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "praw = 6.5.1\n",
      "pandas = 1.0.3\n",
      "spacy = 2.2.4\n",
      "python version = 3.7.7\n"
     ]
    }
   ],
   "source": [
    "print(f'praw = {praw.__version__}')\n",
    "print(f'pandas = {pd.__version__}')\n",
    "print(f'spacy = {spacy.__version__}')\n",
    "from platform import python_version\n",
    "print(f'python version = {python_version()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012227,
     "end_time": "2020-03-29T11:46:56.090466",
     "exception": false,
     "start_time": "2020-03-29T11:46:56.078239",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Set up the Python Reddit API Wrapper (PRAW)\n",
    "You need a user account - it's fine to create a brand new one.\n",
    "\n",
    "A really useful library that allows querying of Reddit's API in python.  \n",
    "Check the documentation and follow the steps to generate your app client and find your client ID and client Secret  \n",
    "https://praw.readthedocs.io/en/latest/getting_started/quick_start.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012264,
     "end_time": "2020-03-29T11:46:56.115127",
     "exception": false,
     "start_time": "2020-03-29T11:46:56.102863",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Save Secrets with treebeard\n",
    "\n",
    "I want to save my reddit credentials separately from my code and this notebook.  \n",
    "Create a JSON file with a dictionary of the reddit app secrets, and then upload with `treebeard secrets push secrets.json`  \n",
    "Ignore the file in `.gitignore` and `treebeard.yaml` so it does not get stored with the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 0.018878,
     "end_time": "2020-03-29T11:46:56.146333",
     "exception": false,
     "start_time": "2020-03-29T11:46:56.127455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Don't save your creds in code! This is an example just to show how to construct the JSON file.\n",
    "my_creds = {'username': 'my_username', \n",
    "            'password': 'my_password', \n",
    "            'app_client_id': 'app_client_ID', \n",
    "            'app_client_secret': 'app_client_secret'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 0.021236,
     "end_time": "2020-03-29T11:46:56.180009",
     "exception": false,
     "start_time": "2020-03-29T11:46:56.158773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('dummy_secrets.json', 'w') as f:\n",
    "    f.write(json.dumps(my_creds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 0.159863,
     "end_time": "2020-03-29T11:46:56.354222",
     "exception": false,
     "start_time": "2020-03-29T11:46:56.194359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"username\": \"my_username\", \"password\": \"my_password\", \"app_client_id\": \"app_client_ID\", \"app_client_secret\": \"app_client_secret\"}"
     ]
    }
   ],
   "source": [
    "!cat dummy_secrets.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 1.574621,
     "end_time": "2020-03-29T11:46:57.944981",
     "exception": false,
     "start_time": "2020-03-29T11:46:56.370360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0müå≤ Pushing Secrets for project 63db2b28e1\r\n",
      "\u001b[0m\r\n",
      "\r\n",
      "\u001b[0m  Including dummy_secrets.json\r\n",
      "\u001b[0m  Including secrets.json\r\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîê  done!\r\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!treebeard secrets push dummy_secrets.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014642,
     "end_time": "2020-03-29T11:46:57.976930",
     "exception": false,
     "start_time": "2020-03-29T11:46:57.962288",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This ensures secrets are available across any cloud project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 1.331734,
     "end_time": "2020-03-29T11:46:59.322864",
     "exception": false,
     "start_time": "2020-03-29T11:46:57.991130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0müå≤ Pushing Secrets for project 63db2b28e1\r\n",
      "\u001b[0m\r\n",
      "\r\n",
      "\u001b[0m  Including secrets.json\r\n",
      "\u001b[0m  Including secrets.json\r\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîê  done!\r\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# pushing my real credentials file\n",
    "!treebeard secrets push secrets.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 0.025543,
     "end_time": "2020-03-29T11:46:59.366622",
     "exception": false,
     "start_time": "2020-03-29T11:46:59.341079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('secrets.json', 'r') as f:\n",
    "    secrets = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "papermill": {
     "duration": 0.021521,
     "end_time": "2020-03-29T11:46:59.402856",
     "exception": false,
     "start_time": "2020-03-29T11:46:59.381335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reddit Credentials - add your own by following the steps in the quick start link above.\n",
    "username = secrets['username']\n",
    "password = secrets['password']\n",
    "app_client_id = secrets['app_client_id']\n",
    "app_client_secret = secrets['app_client_secret']\n",
    "user_agent = \"script:my_app:v0.1 (by u/laurence_treebeard)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "papermill": {
     "duration": 1.55763,
     "end_time": "2020-03-29T11:47:00.974620",
     "exception": false,
     "start_time": "2020-03-29T11:46:59.416990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id=app_client_id,\n",
    "                     client_secret=app_client_secret,\n",
    "                     user_agent=user_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "papermill": {
     "duration": 0.023938,
     "end_time": "2020-03-29T11:47:01.016601",
     "exception": false,
     "start_time": "2020-03-29T11:47:00.992663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check we have a reddit read_only instance\n",
    "print(reddit.read_only)  # Output: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "papermill": {
     "duration": 0.580861,
     "end_time": "2020-03-29T11:47:01.612623",
     "exception": true,
     "start_time": "2020-03-29T11:47:01.031762",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ResponseException",
     "evalue": "received 401 HTTP response",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResponseException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-acc0e49351f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check we can query reddit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# options: controversial, gilded, hot, new, rising, top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msubmission\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreddit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubreddit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'learnpython'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reddit_tracker-EVWoW8Ms/lib/python3.7/site-packages/praw/models/listing/generator.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_listing\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_list_index\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_listing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_list_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reddit_tracker-EVWoW8Ms/lib/python3.7/site-packages/praw/models/listing/generator.py\u001b[0m in \u001b[0;36m_next_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_listing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reddit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_listing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_listing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_listing\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# for submission duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reddit_tracker-EVWoW8Ms/lib/python3.7/site-packages/praw/reddit.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, path, params)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \"\"\"\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjectify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reddit_tracker-EVWoW8Ms/lib/python3.7/site-packages/praw/reddit.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, path, params, data, files)\u001b[0m\n\u001b[1;32m    625\u001b[0m         \"\"\"\n\u001b[1;32m    626\u001b[0m         return self._core.request(\n\u001b[0;32m--> 627\u001b[0;31m             \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m         )\n\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reddit_tracker-EVWoW8Ms/lib/python3.7/site-packages/prawcore/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, path, data, files, json, params)\u001b[0m\n\u001b[1;32m    183\u001b[0m         return self._request_with_retries(\n\u001b[1;32m    184\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             params=params, url=url)\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reddit_tracker-EVWoW8Ms/lib/python3.7/site-packages/prawcore/sessions.py\u001b[0m in \u001b[0;36m_request_with_retries\u001b[0;34m(self, data, files, json, method, params, url, retries)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         response, saved_exception = self._make_request(\n\u001b[0;32m--> 116\u001b[0;31m             data, files, json, method, params, retries, url)\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mdo_retry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reddit_tracker-EVWoW8Ms/lib/python3.7/site-packages/prawcore/sessions.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, data, files, json, method, params, retries, url)\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_requestor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_header_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 params=params)\n\u001b[0m\u001b[1;32m    102\u001b[0m             log.debug('Response: {} ({} bytes)'.format(\n\u001b[1;32m    103\u001b[0m                 response.status_code, response.headers.get('content-length')))\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reddit_tracker-EVWoW8Ms/lib/python3.7/site-packages/prawcore/rate_limit.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, request_function, set_header_callback, *args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \"\"\"\n\u001b[1;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'headers'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_header_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reddit_tracker-EVWoW8Ms/lib/python3.7/site-packages/prawcore/sessions.py\u001b[0m in \u001b[0;36m_set_header_callback\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    143\u001b[0m         if not self._authorizer.is_valid() and hasattr(self._authorizer,\n\u001b[1;32m    144\u001b[0m                                                        'refresh'):\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_authorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         return {'Authorization': 'bearer {}'\n\u001b[1;32m    147\u001b[0m                 .format(self._authorizer.access_token)}\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reddit_tracker-EVWoW8Ms/lib/python3.7/site-packages/prawcore/auth.py\u001b[0m in \u001b[0;36mrefresh\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;34m\"\"\"Obtain a new ReadOnly access token.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrant_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'client_credentials'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reddit_tracker-EVWoW8Ms/lib/python3.7/site-packages/prawcore/auth.py\u001b[0m in \u001b[0;36m_request_token\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    136\u001b[0m                const.ACCESS_TOKEN_PATH)\n\u001b[1;32m    137\u001b[0m         \u001b[0mpre_request_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_authenticator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0mpayload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpayload\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Why are these OKAY responses?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/reddit_tracker-EVWoW8Ms/lib/python3.7/site-packages/prawcore/auth.py\u001b[0m in \u001b[0;36m_post\u001b[0;34m(self, url, success_status, **data)\u001b[0m\n\u001b[1;32m     29\u001b[0m                                            data=sorted(data.items()))\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msuccess_status\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mResponseException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResponseException\u001b[0m: received 401 HTTP response"
     ]
    }
   ],
   "source": [
    "# Check we can query reddit\n",
    "# options: controversial, gilded, hot, new, rising, top\n",
    "for submission in reddit.subreddit('learnpython').hot(limit=5):\n",
    "    print(submission.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "You've now queried the Reddit API!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Using SpaCy\n",
    "\n",
    "SpaCy can recognise a range of named entities:  \n",
    "https://spacy.io/api/annotation#named-entities  \n",
    "- PERSON\tPeople, including fictional.\n",
    "- NORP\tNationalities or religious or political groups.\n",
    "- FAC\tBuildings, airports, highways, bridges, etc.\n",
    "- ORG\tCompanies, agencies, institutions, etc.\n",
    "- GPE\tCountries, cities, states.\n",
    "- LOC\tNon-GPE locations, mountain ranges, bodies of water.\n",
    "- PRODUCT\tObjects, vehicles, foods, etc. (Not services.)\n",
    "- EVENT\tNamed hurricanes, battles, wars, sports events, etc.\n",
    "- WORK_OF_ART\tTitles of books, songs, etc.\n",
    "- LAW\tNamed documents made into laws.\n",
    "- LANGUAGE\tAny named language.\n",
    "- DATE\tAbsolute or relative dates or periods.\n",
    "- TIME\tTimes smaller than a day.\n",
    "- PERCENT\tPercentage, including ‚Äù%‚Äú.\n",
    "- MONEY\tMonetary values, including unit.\n",
    "- QUANTITY\tMeasurements, as of weight or distance.\n",
    "- ORDINAL\t‚Äúfirst‚Äù, ‚Äúsecond‚Äù, etc.\n",
    "- CARDINAL\tNumerals that do not fall under another type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load SpaCy's text model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test SpaCy and render the output - shiny!\n",
    "doc = nlp(\"Apple is looking at buying a U.K. startup for $1 billion\")\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Turn this into a helpful function for later\n",
    "def spacy_extract(df, label = 'PERSON'):\n",
    "    '''\n",
    "    Takes a pandas Dataframe object and a named entity label\n",
    "    Returns an array of arrays for each reddit submission\n",
    "    in the dataframe.\n",
    "    '''\n",
    "    titles = df['title']\n",
    "    output = [] # output\n",
    "    for title in titles:\n",
    "        names = [] \n",
    "        title = title.replace(\"'s\", \"\") # clear out apostrophe's\n",
    "        doc = nlp(title)\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == label:\n",
    "                names.append(ent.text)\n",
    "        output.append(names)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Querying Reddit\n",
    "Input types:  \n",
    "- subreddit\n",
    "- new or hot or top\n",
    "- entity types: person, organisation, organisation, product etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test out a query\n",
    "# Try replacing top with new - but you'll have to remove the time_filter as it always takes the most recent\n",
    "df = pd.DataFrame([[x.title, x.score, x.id, x.url] for x in reddit.subreddit('nba').top(limit=100, time_filter='week')], columns=['title', 'score', 'id', 'url'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test SpaCy on Reddit submission titles\n",
    "for x in df['title'][:10]:\n",
    "    doc = nlp(x)\n",
    "    displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Create functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot(df):\n",
    "    ''' \n",
    "    Given an input dataframe plot a horizontal bar chart\n",
    "    df: pandas dataframe with two columns, 'Names' and 'Count'\n",
    "    look_for: string, SpaCy entity type\n",
    "    subreddit: string, name of subreddit\n",
    "    '''\n",
    "    df = df[:20].iloc[::-1].reset_index()\n",
    "    fig = px.bar(df, x=\"Count\", y=\"Names\", orientation='h')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_subreddit(subreddit='news', look_for='PERSON', sort='top', limit=100, time_filter='month'):\n",
    "    '''\n",
    "    Sort can be 'top' or 'hot' or 'new'\n",
    "    Limit should be max 1000\n",
    "    Time_filter can be 'hour', day', 'week', 'month', 'year', 'all'\n",
    "    If 'new' is selected, time_filter is unused\n",
    "    '''\n",
    "    if limit > 1000:\n",
    "        print('Limit should be less than or equal to 1000')\n",
    "        return\n",
    "    \n",
    "    time_filters = ['hour', 'day', 'week', 'month', 'year', 'all']\n",
    "    if time_filter not in time_filters:\n",
    "        print(f'Incorrect time filter. Expecting one of {time_filters}')\n",
    "    \n",
    "    columns = ['title', 'score', 'id', 'url', 'datetime']\n",
    "    if sort=='hot':\n",
    "        df = pd.DataFrame([[x.title, x.score, x.id, x.url, datetime.fromtimestamp(x.created_utc, timezone.utc)] \\\n",
    "                           for x in reddit.subreddit(subreddit).hot(limit=limit, time_filter=time_filter)],\n",
    "                    columns=columns)\n",
    "    elif sort=='new':\n",
    "        df = pd.DataFrame([[x.title, x.score, x.id, x.url, datetime.fromtimestamp(x.created_utc, timezone.utc)] \\\n",
    "                           for x in reddit.subreddit(subreddit).new(limit=limit)],\n",
    "                  columns=columns)\n",
    "    else:\n",
    "        df = pd.DataFrame([[x.title, x.score, x.id, x.url, datetime.fromtimestamp(x.created_utc, timezone.utc)] \\\n",
    "                           for x in reddit.subreddit(subreddit).top(limit=limit, time_filter=time_filter)],\n",
    "              columns=columns)\n",
    "        \n",
    "    print(f'{len(df)} submissions found')\n",
    "    print(f'Extracting {look_for}s')\n",
    "    df['data'] = spacy_extract(df, label=look_for)\n",
    "    \n",
    "    # Return top 10\n",
    "    flat_list = [item for sublist in df['data'] for item in sublist]\n",
    "    c = Counter(flat_list)\n",
    "    top = pd.DataFrame(c.most_common(), columns=['Names', 'Count'])\n",
    "    \n",
    "    chart = plot(top) # plot chart\n",
    "    return df, top, chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%timeit -n 1 -r 1\n",
    "df, top, chart = get_subreddit(subreddit='nba', look_for='PERSON', sort='top', limit=999, time_filter='week')\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "subreddits_to_query = [\"soccer\",\"baseball\",\"hockey\",\"mma\",\"running\",\"snowboarding\",\n",
    "                       \"climbing\",\"nba\",\"nfl\",\"politics\",\"casualuk\",\"news\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ensure there is a local directory to save images in\n",
    "if not os.path.exists('output'):\n",
    "    os.makedirs('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save all the images locally\n",
    "for subreddit in subreddits_to_query:\n",
    "    df, top, chart = get_subreddit(subreddit=subreddit, look_for='PERSON', sort='top', limit=999, time_filter='week')\n",
    "    name = f\"{subreddit}.html\"\n",
    "    chart.write_html(f'output/{name}') # save image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "papermill": {
   "duration": 24.828451,
   "end_time": "2020-03-29T11:47:01.717171",
   "environment_variables": {},
   "exception": true,
   "input_path": "main.ipynb",
   "output_path": "out.ipynb",
   "parameters": {},
   "start_time": "2020-03-29T11:46:36.888720",
   "version": "2.0.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}